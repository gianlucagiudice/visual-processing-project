{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from os import path\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "METADATA_DESTINATION = '../dataset/imdb_crop/'\n",
    "METADATA_CROPPED_FILE_MATLAB = METADATA_DESTINATION + 'imdb.mat'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# RETRIEVING NAMES AND IMG URLS\\nnames = open(\\'names.html\\', \\'r\\', errors=\\'ignore\\')\\nactors = open(\"most_famous_actors.txt\", \\'w\\')\\n\\nactors_names = []\\nimg_urls = []\\nsoup = BeautifulSoup(names, \\'html.parser\\')\\nfor span in soup.findAll(\\'span\\'):\\n    for img in span.findAll(\\'img\\'):\\n        if img:\\n            actors_names.append(img.attrs[\\'alt\\'])\\n            img_urls.append(re.split(r\\' |,\\', img.attrs[\\'srcset\\'])[-2])\\n\\nfor i in range(len(actors_names)):\\n    actors.write(actors_names[i] + \\';\\' + img_urls[i] + \\'\\n\\')\\n'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# RETRIEVING NAMES AND IMG URLS\n",
    "names = open('names.html', 'r', errors='ignore')\n",
    "actors = open(\"most_famous_actors.txt\", 'w')\n",
    "\n",
    "actors_names = []\n",
    "img_urls = []\n",
    "soup = BeautifulSoup(names, 'html.parser')\n",
    "for span in soup.findAll('span'):\n",
    "    for img in span.findAll('img'):\n",
    "        if img:\n",
    "            actors_names.append(img.attrs['alt'])\n",
    "            img_urls.append(re.split(r' |,', img.attrs['srcset'])[-2])\n",
    "\n",
    "for i in range(len(actors_names)):\n",
    "    actors.write(actors_names[i] + ';' + img_urls[i] + '\\n')\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "actors = open(\"most_famous_actors.txt\", 'r')\n",
    "actors = actors.read()\n",
    "actors_names = re.split(r';|\\n', actors)[::2]\n",
    "actors_names = actors_names[:-1]\n",
    "actors_img_urls = re.split(r';|\\n', actors)[1::2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# MOST FAMOUS ACTORS IN IMDB\\nhead, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\\npath_serialized = path.join(head, \\'imdb.pickle\\')\\ndf = pd.read_pickle(path_serialized)\\ndf.head()\\n\\ndf_actors_imdb = pd.DataFrame(columns=[\\'name\\', \\'url_image\\', \\'gender\\', \\'age\\'])\\nwith tqdm(total=len(actors_names)) as pbar:\\n        for i in range(len(actors_names)):\\n            q = \\'name==\"\\' + actors_names[i] + \\'\"\\'\\n            query_results = df.query(q)[[\"age\",\"gender\"]]\\n            if not query_results.empty:\\n                new_row = query_results.iloc[0]\\n                new_row[\\'name\\'] = actors_names[i]\\n                new_row[\\'url_img\\'] = actors_img_urls[i]\\n                df_actors_imdb = df_actors_imdb.append(new_row)\\n            pbar.update(1)\\ndf_actors_imdb.reset_index()\\n\\nlen(df_actors_imdb)\\n\\n\\nhead, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\\npath_serialized = path.join(head, \\'imdb_most_famous_actors.pickle\\')\\n#df_actors_imdb.to_pickle(path_serialized)\\n\\ndf_actors_imdb = pd.read_pickle(path_serialized)\\ndf_actors_imdb.head()\\n\\ndf_actors_imdb.describe(include=\\'all\\')\\n# female 0, male 1\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# MOST FAMOUS ACTORS IN IMDB\n",
    "head, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\n",
    "path_serialized = path.join(head, 'imdb.pickle')\n",
    "df = pd.read_pickle(path_serialized)\n",
    "df.head()\n",
    "\n",
    "df_actors_imdb = pd.DataFrame(columns=['name', 'url_img', 'gender', 'age'])\n",
    "with tqdm(total=len(actors_names)) as pbar:\n",
    "        for i in range(len(actors_names)):\n",
    "            q = 'name==\"' + actors_names[i] + '\"'\n",
    "            query_results = df.query(q)[[\"age\",\"gender\"]]\n",
    "            if not query_results.empty:\n",
    "                new_row = query_results.iloc[0]\n",
    "                new_row['name'] = actors_names[i]\n",
    "                new_row['url_img'] = actors_img_urls[i]\n",
    "                df_actors_imdb = df_actors_imdb.append(new_row)\n",
    "            pbar.update(1)\n",
    "df_actors_imdb.reset_index()\n",
    "\n",
    "len(df_actors_imdb)\n",
    "\n",
    "\n",
    "head, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\n",
    "path_serialized = path.join(head, 'imdb_most_famous_actors.pickle')\n",
    "#df_actors_imdb.to_pickle(path_serialized)\n",
    "\n",
    "df_actors_imdb = pd.read_pickle(path_serialized)\n",
    "df_actors_imdb.head()\n",
    "\n",
    "df_actors_imdb.describe(include='all')\n",
    "# female 0, male 1\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "'''\n",
    "# MOST FAMOUS ACTORS IN WIKIDATA\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# not so inclusive :/\n",
    "gender_dict = {'http://www.wikidata.org/entity/Q6581097': 1,\n",
    "               'http://www.wikidata.org/entity/Q6581072': 0,\n",
    "               'http://www.wikidata.org/entity/Q2449503': 1,\n",
    "               'https://www.wikidata.org/wiki/Q1052281': 0}\n",
    "\n",
    "def do_query(an, aiu):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    gender_dict = {'http://www.wikidata.org/entity/Q6581097': 1, 'http://www.wikidata.org/entity/Q6581072': 0 }\n",
    "    df_actors_wiki = pd.DataFrame(columns=['name', 'url_img', 'gender', 'age'])\n",
    "    with tqdm(total=len(an)) as pbar:\n",
    "        for i in range(len(an)):\n",
    "            q = \"SELECT  DISTINCT ?gender (SAMPLE(?birth) as ?birth_date)\" \\\n",
    "            \" (SAMPLE(?death_date) as ?dateOfDeath)  WHERE {\" \\\n",
    "            \"?id wdt:P31 wd:Q5.\" \\\n",
    "            \"?id wdt:P569 ?birth .\" \\\n",
    "            \"?id wdt:P21 ?gender.\" \\\n",
    "            \"OPTIONAL{?id wdt:P570 ?death_date .}\" \\\n",
    "            \"SERVICE wikibase:label {\" \\\n",
    "            \"bd:serviceParam wikibase:language 'en'.\" \\\n",
    "            \"?id rdfs:label ?idLabel .\" \\\n",
    "            \"}?id ?label\\\"\"  + an[i] + \\\n",
    "            \"\\\"@en.\" \\\n",
    "            \"}\" \\\n",
    "            \"GROUP BY ?gender\"\n",
    "            sparql.setQuery(q)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            results_df = pd.io.json.json_normalize(results['results']['bindings'])\n",
    "            if not results_df.empty and len(results_df) == 1:\n",
    "                if results_df[\"gender.value\"].iloc[0] in gender_dict.values():\n",
    "                    gender = gender_dict[results_df[\"gender.value\"].iloc[0]]\n",
    "                    birth_date = datetime.strptime(results_df[\"birth_date.value\"].iloc[0],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                    age = relativedelta(datetime.now(), birth_date).years\n",
    "                    new_row = {\"name\": an[i], \"url_img\": aiu[i], \"gender\": gender, \"age\": age}\n",
    "                    df_actors_wiki = df_actors_wiki.append(new_row, ignore_index=True)\n",
    "            pbar.update(1)\n",
    "    df_actors_wiki.reset_index()\n",
    "    return df_actors_wiki\n",
    "\n",
    "# to handle 'Too Many Requests' errors\n",
    "df1 = do_query(actors_names[:200], actors_img_urls[:200])\n",
    "sleep(60)\n",
    "df2 = do_query(actors_names[200:400], actors_img_urls[200:400])\n",
    "sleep(60)\n",
    "df3 = do_query(actors_names[400:600], actors_img_urls[400:600])\n",
    "sleep(60)\n",
    "df4 = do_query(actors_names[600:800], actors_img_urls[600:800])\n",
    "sleep(60)\n",
    "df5 = do_query(actors_names[800:1000], actors_img_urls[800:1000])\n",
    "sleep(60)\n",
    "df6 = do_query(actors_names[1000:1200], actors_img_urls[1000:1200])\n",
    "sleep(60)\n",
    "df7 = do_query(actors_names[1200:1400], actors_img_urls[1200:1400])\n",
    "sleep(60)\n",
    "df8 = do_query(actors_names[1400:], actors_img_urls[1400:])\n",
    "df_actors_wiki = df1\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df2])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df3])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df4])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df5])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df6])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df7])\n",
    "df_actors_wiki = pd.concat([df_actors_wiki, df8])\n",
    "df_actors_wiki.head()\n",
    "\n",
    "head, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\n",
    "path_serialized = path.join(head, 'wiki_most_famous_actors.pickle')\n",
    "#df_actors_wiki.to_pickle(path_serialized)\n",
    "\n",
    "df_actors_wiki = pd.read_pickle(path_serialized)\n",
    "df_actors_wiki.head()\n",
    "\n",
    "df_actors_wiki.describe(include='all')\n",
    "# female 0, male 1\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# COMPARISON\n",
    "head, tail = path.split(METADATA_CROPPED_FILE_MATLAB)\n",
    "path_serialized_wiki = path.join(head, 'wiki_most_famous_actors.pickle')\n",
    "path_serialized_imdb = path.join(head, 'imdb_most_famous_actors.pickle')\n",
    "df_actors_imdb = pd.read_pickle(path_serialized_imdb)\n",
    "df_actors_wiki = pd.read_pickle(path_serialized_wiki)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length IMDB: 1245, length WIKI: 969\n"
     ]
    }
   ],
   "source": [
    "print('Length IMDB: ' + str(len(df_actors_imdb)) + ', length WIKI: ' + str(len(df_actors_wiki)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                name gender age  \\\n102     Elle Fanning      0  23   \n148          Zendaya      0  25   \n91     Sophie Turner      0  25   \n174  Maisie Williams      0  24   \n\n                                               url_img  \n102  https://d3hjzzsa8cr26l.cloudfront.net/e6f09cc1...  \n148  https://d3hjzzsa8cr26l.cloudfront.net/fe3a1254...  \n91   https://d3hjzzsa8cr26l.cloudfront.net/6579d712...  \n174  https://d3hjzzsa8cr26l.cloudfront.net/49381f7d...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>url_img</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>102</th>\n      <td>Elle Fanning</td>\n      <td>0</td>\n      <td>23</td>\n      <td>https://d3hjzzsa8cr26l.cloudfront.net/e6f09cc1...</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Zendaya</td>\n      <td>0</td>\n      <td>25</td>\n      <td>https://d3hjzzsa8cr26l.cloudfront.net/fe3a1254...</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Sophie Turner</td>\n      <td>0</td>\n      <td>25</td>\n      <td>https://d3hjzzsa8cr26l.cloudfront.net/6579d712...</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>Maisie Williams</td>\n      <td>0</td>\n      <td>24</td>\n      <td>https://d3hjzzsa8cr26l.cloudfront.net/49381f7d...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}